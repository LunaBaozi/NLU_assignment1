{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Understanding\n",
    "## Assignment 1: dependency grammars\n",
    "The following requests have been fulfilled:\n",
    "1. Extract a path of dependency relations from the root to a token;\n",
    "2. Extract subtree of a dependent given a token;\n",
    "3. Check if a given list of token (segment or sentence) forms a subtree;\n",
    "4. Identify the head of a span, given its tokens;\n",
    "5. Extract sentence subject, direct object and indirect object spans.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rationale\n",
    "Python code has been written in order to exploit the vast functionality of `spaCy` functions. Detailed comments on the logic behind each function can be found on the `assignment1.py` file itself; here we will present a higher level explanation of the code.\n",
    "The code has the main purpose of exploring and working with dependency graphs through `spaCy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `path_root_token(sentence)`\n",
    "The function takes as input a tokenized sentence and outputs the dependency relations from the root to each token of the sentence, in the form of a dictionary structured in the following way:\n",
    "1. Keys are the tokens of the tokenized sentence;\n",
    "2. Values are lists of dictionaries, having as key the dependency relation of the token and as value the token itself.\n",
    "An example is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Apple is looking at buying U.K. startup for 1$ billion'\n",
    "## The sentence is tokenized with spacy\n",
    "## The sentence is passed to the function\n",
    "## Output (partial):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [...]\n",
    "# looking []\n",
    "# at      [{'ROOT': looking}]\n",
    "# buying  [{'ROOT': looking}, {'prep': at}]\n",
    "# U.K.    [{'ROOT': looking}, {'prep': at}, {'pcomp': buying}]\n",
    "# [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the nested dictionaries are sorted in order from `ROOT` to each token, and that the dependency relations of the tokens are accessed through the spaCy `token.ancestors` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function `extract_subtree(sentence)`\n",
    "The function takes as input a tokenized sentence and outputs a list of sentence subtrees for each token. The tokens subtrees are accessed through the spaCy `token.subtree` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions `check_subtree(sentence, token_list)` and `compare(token_list, string_list)`\n",
    "The function `check_subtree(sentence, token_list)` checks whether a given list of tokens (of `str` type) forms a subtree of the input sentence. It does so by first calling the `extract_subtree(sentence)` function, and then by calling a helper function, `compare(token_list, string_list)`, whose only purpose is to ensure that the list of tokens in input contains the same objects as the list of strings in input. It first ensures that the two lists have equal length - in order to be more computationally efficient - and if so, it proceeds to compare each object of the two lists. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output:\n",
    "## The tokens ['buying', 'U.K.'] form a subtree of the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function `get_head_span(span)` \n",
    "The function takes as input a tokenized span of a sentence and outputs the head of that span. It makes use of the `spaCy` `token.children` function in order to retrieve the complete list of children of each token, appending it to the value of a dictionary having the token as key. It then proceeds to sort the dictionary in decreasing order according to the length of the lists in the values; the list having more tokens corresponds to the token having more children. The first child is thus extracted as the head of the span. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output:\n",
    "## The head of the span is: looking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function `subj_obj_span(sentence)`\n",
    "The function takes as input a tokenized sentence and outputs a dictionary structured in the following way:\n",
    "1. Keys are the syntactic dependency relations of interest;\n",
    "2. Values are the lists of the spans of the keys.\n",
    "We are interested in finding the sentence subject, the sentence direct object and the sentence indirect object.\n",
    "\n",
    "Note that the function makes use of the `spaCy` function `token.descendants` to extract a local span of the token of interest. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output:\n",
    "## nsubj ['Apple']\n",
    "## dobj  ['U.K.']\n",
    "## pobj  ['$ 1 billion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "The testing is implemented as a very simple sequence of prints, in order to obtain a visual output that can be easily compared with the expectations of the user or other outputs from different tools.\n",
    "We supply a test sentence that can be also found in the `spaCy` documentation, which is: \"Apple is looking at buying U.K. startup for $1 billion\".\n",
    "We provide a polished visual output by manipulating the dictionaries and lists to create simple but well-separated table entries.\n",
    "The whole testing can be executed by the executiong of the same `assignment1.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
